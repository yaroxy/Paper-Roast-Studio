
<table border=1 style='margin: auto; width: max-content;'><tr><td style='text-align: center;'>Model</td><td style='text-align: center;'>MathVista</td><td style='text-align: center;'>MathVision</td><td style='text-align: center;'>MathVerse</td><td style='text-align: center;'>DynaMath</td><td style='text-align: center;'>WeMath</td><td style='text-align: center;'>LogicVista</td><td style='text-align: center;'>Average</td></tr><tr><td colspan="8">Close-source Models</td></tr><tr><td style='text-align: center;'>Gemini-2.0-Flash</td><td style='text-align: center;'>70.4</td><td style='text-align: center;'>47.8</td><td style='text-align: center;'>43.6</td><td style='text-align: center;'>42.1</td><td style='text-align: center;'>47.4</td><td style='text-align: center;'>52.3</td><td style='text-align: center;'>50.6</td></tr><tr><td style='text-align: center;'>Gemini-2.0-Pro</td><td style='text-align: center;'>71.3</td><td style='text-align: center;'>48.1</td><td style='text-align: center;'>67.3</td><td style='text-align: center;'>43.3</td><td style='text-align: center;'>56.5</td><td style='text-align: center;'>53.2</td><td style='text-align: center;'>56.6</td></tr><tr><td style='text-align: center;'>GPT-4.1-20250414</td><td style='text-align: center;'>70.4</td><td style='text-align: center;'>45.1</td><td style='text-align: center;'>48.9</td><td style='text-align: center;'>43.3</td><td style='text-align: center;'>55.5</td><td style='text-align: center;'>61.1</td><td style='text-align: center;'>54.0</td></tr><tr><td style='text-align: center;'>GPT-4o-latest</td><td style='text-align: center;'>71.6</td><td style='text-align: center;'>43.8</td><td style='text-align: center;'>49.9</td><td style='text-align: center;'>48.5</td><td style='text-align: center;'>50.6</td><td style='text-align: center;'>64.4</td><td style='text-align: center;'>54.8</td></tr><tr><td style='text-align: center;'>Claude-3.7-Sonnet</td><td style='text-align: center;'>66.8</td><td style='text-align: center;'>41.3</td><td style='text-align: center;'>52.0</td><td style='text-align: center;'>39.7</td><td style='text-align: center;'>58.2</td><td style='text-align: center;'>49.3</td><td style='text-align: center;'>49.6</td></tr><tr><td colspan="8">Open-source Models</td></tr><tr><td style='text-align: center;'>OVR-7B</td><td style='text-align: center;'>72.1</td><td style='text-align: center;'>51.8</td><td style='text-align: center;'>54.6</td><td style='text-align: center;'>33.5</td><td style='text-align: center;'>44.6</td><td style='text-align: center;'>54.8</td><td style='text-align: center;'>51.9</td></tr><tr><td style='text-align: center;'>WeThink-7B</td><td style='text-align: center;'>70.9</td><td style='text-align: center;'>27.2</td><td style='text-align: center;'>44.7</td><td style='text-align: center;'>24.4</td><td style='text-align: center;'>48.0</td><td style='text-align: center;'>53.0</td><td style='text-align: center;'>44.7</td></tr><tr><td style='text-align: center;'>Qwen2.5-VL-7B</td><td style='text-align: center;'>68.1</td><td style='text-align: center;'>25.4</td><td style='text-align: center;'>41.1</td><td style='text-align: center;'>21.8</td><td style='text-align: center;'>36.2</td><td style='text-align: center;'>47.9</td><td style='text-align: center;'>40.1</td></tr><tr><td style='text-align: center;'>Qwen2.5-VL-72B</td><td style='text-align: center;'>74.2</td><td style='text-align: center;'>39.3</td><td style='text-align: center;'>47.3</td><td style='text-align: center;'>35.9</td><td style='text-align: center;'>49.1</td><td style='text-align: center;'>55.7</td><td style='text-align: center;'>50.2</td></tr><tr><td style='text-align: center;'>InternVL3-8B</td><td style='text-align: center;'>70.5</td><td style='text-align: center;'>30.0</td><td style='text-align: center;'>38.5</td><td style='text-align: center;'>25.7</td><td style='text-align: center;'>39.5</td><td style='text-align: center;'>44.5</td><td style='text-align: center;'>41.4</td></tr><tr><td style='text-align: center;'>InternVL3-78B</td><td style='text-align: center;'>79.0</td><td style='text-align: center;'>38.8</td><td style='text-align: center;'>51.0</td><td style='text-align: center;'>35.1</td><td style='text-align: center;'>46.1</td><td style='text-align: center;'>55.9</td><td style='text-align: center;'>51.0</td></tr><tr><td style='text-align: center;'>VL-Rethinker-7B</td><td style='text-align: center;'>73.7</td><td style='text-align: center;'>28.4</td><td style='text-align: center;'>46.4</td><td style='text-align: center;'>17.8</td><td style='text-align: center;'>36.3</td><td style='text-align: center;'>42.7</td><td style='text-align: center;'>40.9</td></tr><tr><td style='text-align: center;'>VLAA-Thinker-7B</td><td style='text-align: center;'>68.0</td><td style='text-align: center;'>26.4</td><td style='text-align: center;'>48.2</td><td style='text-align: center;'>22.4</td><td style='text-align: center;'>41.5</td><td style='text-align: center;'>48.5</td><td style='text-align: center;'>42.5</td></tr><tr><td style='text-align: center;'>OpenVLThinker-7B</td><td style='text-align: center;'>65.3</td><td style='text-align: center;'>23.0</td><td style='text-align: center;'>38.1</td><td style='text-align: center;'>16.8</td><td style='text-align: center;'>35.2</td><td style='text-align: center;'>44.5</td><td style='text-align: center;'>37.2</td></tr><tr><td style='text-align: center;'>Keye-VL-8B-Thinking</td><td style='text-align: center;'>77.2</td><td style='text-align: center;'>43.7</td><td style='text-align: center;'>53.4</td><td style='text-align: center;'>37.1</td><td style='text-align: center;'>60.2</td><td style='text-align: center;'>49.2</td><td style='text-align: center;'>53.5</td></tr><tr><td style='text-align: center;'>Kimi-VL-A3B-Thinking-2506</td><td style='text-align: center;'>79.5</td><td style='text-align: center;'>53.6</td><td style='text-align: center;'>55.2</td><td style='text-align: center;'>29.1</td><td style='text-align: center;'>45.4</td><td style='text-align: center;'>47.2</td><td style='text-align: center;'>51.7</td></tr><tr><td style='text-align: center;'>SAIL-VL2-2B-Thinking</td><td style='text-align: center;'>68.5</td><td style='text-align: center;'>27.5</td><td style='text-align: center;'>43.4</td><td style='text-align: center;'>20.2</td><td style='text-align: center;'>38.8</td><td style='text-align: center;'>47.0</td><td style='text-align: center;'>40.9</td></tr><tr><td style='text-align: center;'>SAIL-VL2-8B-Thinking</td><td style='text-align: center;'>75.8</td><td style='text-align: center;'>46.7</td><td style='text-align: center;'>58.9</td><td style='text-align: center;'>33.5</td><td style='text-align: center;'>54.9</td><td style='text-align: center;'>56.4</td><td style='text-align: center;'>54.4</td></tr><tr><td style='text-align: center;'>SAIL-VL2-A3B-Thinking</td><td style='text-align: center;'>73.0</td><td style='text-align: center;'>44.9</td><td style='text-align: center;'>55.7</td><td style='text-align: center;'>34.1</td><td style='text-align: center;'>54.2</td><td style='text-align: center;'>59.7</td><td style='text-align: center;'>53.6</td></tr></table>

<div style="text-align: center;">Table 10: Evaluation results on OpenCompass multimodal reasoning benchmarks. All the results are reported from OpenCompass with the GPT-4o-Mini as the judge model. The best results among open-source models are bolded and the second-best results are underlined.</div>


#### 6.2.3 Multimodal Reasoning Tasks

We evaluate our SAIL-VL2-thinking models on the OpenCompass multimodal reasoning benchmarks to assess their advanced cognitive abilities. This benchmark was chosen because it comprises a diverse set of challenging tasks designed to measure deep reasoning rather than simple object recognition. The included tasks are MathVista (Lu et al., 2023), MathVerse (Mishra et al., 2024), MathVision, LogicVista, WeMath (Fang et al., 2024), and DynaMath. Together, these tests cover a wide range of skills, including visual mathematics, which requires solving math problems presented in images, complex logical reasoning, and dynamic problem-solving.

As shown in Table 10, our models achieve leading results on the OpenCompass benchmark. Our premier dense model, SAIL-VL2-8B-Thinking, establishes a new state-of-the-art for open-source models by securing the top position on the leaderboard with a score of 54.4. Our Mixture-of-Experts (MoE) and smaller dense models also demonstrate exceptional efficiency and performance. Notably, our SAIL-VL2-MoE-Thinking model achieves a high score of 53.6 while using only 3B activated parameters. This result is significant as it shows a strong balance between performance and computational cost. In terms of performance, this score not only surpasses strong closed-source models like Gemini-2.0-Flash (50.6) but is also highly competitive with the top-tier GPT-4o-latest (54.8). It also holds a clear advantage over other open-source MoE models, such as kimi-vl-A3B-thinking-2506 (51.7). Taken together, these results, combined with the strong performance of our dense SAIL-VL2-A3B-Thinking model, validate the overall effectiveness and scalability of our SAIL-VL2-Thinking architecture, confirming its successful implementation in both MoE and dense model configurations.

## 7 Conclusion

In this report, we present SAIL-VL2, an open-suite visionâ€“language foundation model for comprehensive multimodal understanding and reasoning. Through innovations in data curation, progressive training, and architecture, SAIL-VL2 achieves consistent gains in both efficiency and performance. Across 106 benchmarks, it sets state-of-the-art results at the 2B and 8B scales. Notably, SAIL-VL2-2B delivers leading results on MMMU and MathVista, and ranks first on the OpenCompass leaderboard among officially released models under 3B, underscoring its competitiveness as an efficient yet powerful LVM. These findings establish SAIL-VL2 as both a high-performance milestone and a scalable foundation for the open-source multimodal community. Looking forward, we will further enhance the SAIL-VL series through more efficient architectures, comprehensive pre-training strategies, and improved reinforcement learning paradigms, enabling its continuous evolution toward stronger multimodal intelligence.